  <aside class="bg-white">
    <section id="model">
      <div class="container text-center">
          <div class="call-to-action">
            
              <h2>What models perform the best when it comes to forecasting volatility?</h2>
            
              <p> First, we will analyse the daily log returns of the Dow Jones index. <br>
                
                <br>

                <img src="img/Daily_log_ret+volatility.png">
              
              Looking at the ACF and PACF, the only signficant lags seems to be 1 or 2. 
              However, after several tests, we got that no Auto-Regressive process is necessary for the mean model. For the volatility process, 
              the first lag is signficant. This means that the volatility of one day affects the next day. </p> <br>
            
                <img src="img/autocorrelation.png" alt="autocorrelation plot">
            
              <br>
              
              <p> This is all great but let's talk math now. The most efficient model we found is the GARCH(1,1) with zero mean and
              Student's t distributed errors. The formulas of the model are the following: </p>  <br>
            
              <br>
            
              ADD LATEX FORMULAS <br>
            
              <br>
            
              <p> Fitting the model to the data, we got the following results: </p> 

              <table class="simpletable">\n<caption>Zero Mean - GARCH Model Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>DJI</td>           <th>  R-squared:         </th>  <td>   0.000</td> \n</tr>\n<tr>\n  <th>Mean Model:</th>            <td>Zero Mean</td>        <th>  Adj. R-squared:    </th>  <td>   0.012</td> \n</tr>\n<tr>\n  <th>Vol Model:</th>               <td>GARCH</td>          <th>  Log-Likelihood:    </th> <td>   4.39503</td>\n</tr>\n<tr>\n  <th>Distribution:</th>  <td>Standardized Student\'s t</td> <th>  AIC:               </th> <td> -0.790064</td>\n</tr>\n<tr>\n  <th>Method:</th>           <td>Maximum Likelihood</td>    <th>  BIC:               </th> <td>   8.83681</td>\n</tr>\n<tr>\n  <th></th>                           <td></td>             <th>  No. Observations:  </th>     <td>82</td>    \n</tr>\n<tr>\n  <th>Date:</th>              <td>Fri, Dec 18 2020</td>     <th>  Df Residuals:      </th>     <td>78</td>    \n</tr>\n<tr>\n  <th>Time:</th>                  <td>17:23:39</td>         <th>  Df Model:          </th>      <td>4</td>    \n</tr>\n</table>\n<table class="simpletable">\n<caption>Volatility Model</caption>\n<tr>\n      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>       <th>P>|t|</th>      <th>95.0% Conf. Int.</th>   \n</tr>\n<tr>\n  <th>omega</th>    <td>1.7646e-03</td> <td>1.492e-03</td> <td>    1.182</td> <td>    0.237</td> <td>[-1.160e-03,4.690e-03]</td>\n</tr>\n<tr>\n  <th>alpha[1]</th> <td>    0.3561</td> <td>7.059e-02</td> <td>    5.044</td> <td>4.553e-07</td>    <td>[  0.218,  0.494]</td>  \n</tr>\n<tr>\n  <th>beta[1]</th>  <td>    0.6439</td> <td>7.236e-02</td> <td>    8.898</td> <td>5.673e-19</td>    <td>[  0.502,  0.786]</td>  \n</tr>\n</table>\n<table class="simpletable">\n<caption>Distribution</caption>\n<tr>\n   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>       <th>P>|t|</th>   <th>95.0% Conf. Int.</th> \n</tr>\n<tr>\n  <th>nu</th> <td>    6.9856</td> <td>    3.506</td> <td>    1.992</td> <td>4.632e-02</td> <td>[  0.114, 13.857]</td>\n</tr>\n</table><br/><br/>Covariance estimator: robust'
            
              <br>
            
              <br>
                                                                          
              <img src="img/basemodel.png" alt="baseline plot" >
          
              <br>
      
              <p> The performance of this GARCH model is already quite good! But let's see if we can further improve it using Google Trends. </p> 
            
          </div>
      </div>
     </section>
  </aside>
